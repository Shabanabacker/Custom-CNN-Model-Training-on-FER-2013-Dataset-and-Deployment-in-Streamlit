{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c28e9b-006b-4ca7-90a5-3c967fa61a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 2.2981, Train Accuracy: 29.27%, Test Accuracy: 41.84%\n",
      "Epoch [2/100], Loss: 1.5487, Train Accuracy: 44.44%, Test Accuracy: 50.20%\n",
      "Epoch [3/100], Loss: 1.4683, Train Accuracy: 49.05%, Test Accuracy: 53.46%\n",
      "Epoch [4/100], Loss: 1.4247, Train Accuracy: 51.78%, Test Accuracy: 55.34%\n",
      "Epoch [5/100], Loss: 1.3941, Train Accuracy: 53.52%, Test Accuracy: 56.34%\n",
      "Epoch [6/100], Loss: 1.3332, Train Accuracy: 56.60%, Test Accuracy: 57.33%\n",
      "Epoch [7/100], Loss: 1.3201, Train Accuracy: 57.15%, Test Accuracy: 58.28%\n",
      "Epoch [8/100], Loss: 1.3111, Train Accuracy: 57.93%, Test Accuracy: 58.79%\n",
      "Epoch [9/100], Loss: 1.2967, Train Accuracy: 58.50%, Test Accuracy: 59.64%\n",
      "Epoch [10/100], Loss: 1.2913, Train Accuracy: 58.79%, Test Accuracy: 60.30%\n",
      "Epoch [11/100], Loss: 1.2561, Train Accuracy: 60.91%, Test Accuracy: 61.08%\n",
      "Epoch [12/100], Loss: 1.2494, Train Accuracy: 60.97%, Test Accuracy: 61.55%\n",
      "Epoch [13/100], Loss: 1.2388, Train Accuracy: 61.94%, Test Accuracy: 61.40%\n",
      "Epoch [14/100], Loss: 1.2341, Train Accuracy: 62.33%, Test Accuracy: 61.99%\n",
      "Epoch [15/100], Loss: 1.2302, Train Accuracy: 62.53%, Test Accuracy: 60.78%\n",
      "Epoch [16/100], Loss: 1.2100, Train Accuracy: 63.46%, Test Accuracy: 63.18%\n",
      "Epoch [17/100], Loss: 1.2040, Train Accuracy: 63.89%, Test Accuracy: 62.94%\n",
      "Epoch [18/100], Loss: 1.1994, Train Accuracy: 63.92%, Test Accuracy: 63.10%\n",
      "Epoch [19/100], Loss: 1.1953, Train Accuracy: 64.34%, Test Accuracy: 63.10%\n",
      "Epoch [20/100], Loss: 1.1897, Train Accuracy: 64.55%, Test Accuracy: 63.15%\n",
      "Epoch [21/100], Loss: 1.1792, Train Accuracy: 65.39%, Test Accuracy: 63.57%\n",
      "Epoch [22/100], Loss: 1.1754, Train Accuracy: 65.39%, Test Accuracy: 63.78%\n",
      "Epoch [23/100], Loss: 1.1731, Train Accuracy: 65.40%, Test Accuracy: 64.08%\n",
      "Epoch [24/100], Loss: 1.1699, Train Accuracy: 65.87%, Test Accuracy: 63.62%\n",
      "Epoch [25/100], Loss: 1.1676, Train Accuracy: 66.00%, Test Accuracy: 64.06%\n",
      "Epoch [26/100], Loss: 1.1609, Train Accuracy: 66.43%, Test Accuracy: 64.06%\n",
      "Epoch [27/100], Loss: 1.1602, Train Accuracy: 66.48%, Test Accuracy: 64.22%\n",
      "Epoch [28/100], Loss: 1.1580, Train Accuracy: 66.35%, Test Accuracy: 64.36%\n",
      "Epoch [29/100], Loss: 1.1553, Train Accuracy: 66.82%, Test Accuracy: 64.13%\n",
      "Epoch [30/100], Loss: 1.1524, Train Accuracy: 66.61%, Test Accuracy: 64.21%\n",
      "Epoch [31/100], Loss: 1.1545, Train Accuracy: 66.43%, Test Accuracy: 64.34%\n",
      "Epoch [32/100], Loss: 1.1498, Train Accuracy: 67.02%, Test Accuracy: 64.36%\n",
      "Epoch [33/100], Loss: 1.1526, Train Accuracy: 66.73%, Test Accuracy: 64.50%\n",
      "Epoch [34/100], Loss: 1.1517, Train Accuracy: 66.86%, Test Accuracy: 64.46%\n",
      "Epoch [35/100], Loss: 1.1476, Train Accuracy: 66.80%, Test Accuracy: 64.18%\n",
      "Epoch [36/100], Loss: 1.1460, Train Accuracy: 67.10%, Test Accuracy: 64.39%\n",
      "Epoch [37/100], Loss: 1.1478, Train Accuracy: 67.06%, Test Accuracy: 64.42%\n",
      "Epoch [38/100], Loss: 1.1464, Train Accuracy: 66.94%, Test Accuracy: 64.38%\n",
      "Epoch [39/100], Loss: 1.1469, Train Accuracy: 66.45%, Test Accuracy: 64.36%\n",
      "Epoch [40/100], Loss: 1.1444, Train Accuracy: 67.22%, Test Accuracy: 64.49%\n",
      "Epoch [41/100], Loss: 1.1486, Train Accuracy: 67.05%, Test Accuracy: 64.22%\n",
      "Epoch [42/100], Loss: 1.1467, Train Accuracy: 67.13%, Test Accuracy: 64.52%\n",
      "Epoch [43/100], Loss: 1.1454, Train Accuracy: 67.13%, Test Accuracy: 64.35%\n",
      "Epoch [44/100], Loss: 1.1447, Train Accuracy: 67.08%, Test Accuracy: 64.17%\n",
      "Epoch [45/100], Loss: 1.1438, Train Accuracy: 67.21%, Test Accuracy: 64.47%\n",
      "Epoch [46/100], Loss: 1.1415, Train Accuracy: 67.41%, Test Accuracy: 64.49%\n",
      "Epoch [47/100], Loss: 1.1403, Train Accuracy: 67.40%, Test Accuracy: 64.63%\n",
      "Epoch [48/100], Loss: 1.1404, Train Accuracy: 67.30%, Test Accuracy: 64.38%\n",
      "Epoch [49/100], Loss: 1.1427, Train Accuracy: 67.31%, Test Accuracy: 64.28%\n",
      "Epoch [50/100], Loss: 1.1414, Train Accuracy: 67.10%, Test Accuracy: 64.41%\n",
      "Epoch [51/100], Loss: 1.1420, Train Accuracy: 67.36%, Test Accuracy: 64.35%\n",
      "Epoch [52/100], Loss: 1.1426, Train Accuracy: 67.15%, Test Accuracy: 64.39%\n",
      "Epoch [53/100], Loss: 1.1415, Train Accuracy: 67.27%, Test Accuracy: 64.41%\n",
      "Epoch [54/100], Loss: 1.1438, Train Accuracy: 67.30%, Test Accuracy: 64.50%\n",
      "Epoch [55/100], Loss: 1.1414, Train Accuracy: 67.67%, Test Accuracy: 64.45%\n",
      "Epoch [56/100], Loss: 1.1436, Train Accuracy: 67.17%, Test Accuracy: 64.53%\n",
      "Epoch [57/100], Loss: 1.1400, Train Accuracy: 67.30%, Test Accuracy: 64.50%\n",
      "Epoch [58/100], Loss: 1.1408, Train Accuracy: 67.40%, Test Accuracy: 64.54%\n",
      "Epoch [59/100], Loss: 1.1460, Train Accuracy: 66.92%, Test Accuracy: 64.49%\n",
      "Epoch [60/100], Loss: 1.1451, Train Accuracy: 66.92%, Test Accuracy: 64.46%\n",
      "Epoch [61/100], Loss: 1.1448, Train Accuracy: 67.07%, Test Accuracy: 64.52%\n",
      "Epoch [62/100], Loss: 1.1419, Train Accuracy: 67.35%, Test Accuracy: 64.50%\n",
      "Epoch [63/100], Loss: 1.1427, Train Accuracy: 67.17%, Test Accuracy: 64.52%\n",
      "Epoch [64/100], Loss: 1.1430, Train Accuracy: 66.75%, Test Accuracy: 64.50%\n",
      "Epoch [65/100], Loss: 1.1414, Train Accuracy: 67.20%, Test Accuracy: 64.53%\n",
      "Epoch [66/100], Loss: 1.1426, Train Accuracy: 67.11%, Test Accuracy: 64.53%\n",
      "Epoch [67/100], Loss: 1.1420, Train Accuracy: 67.46%, Test Accuracy: 64.49%\n",
      "Epoch [68/100], Loss: 1.1436, Train Accuracy: 67.29%, Test Accuracy: 64.49%\n",
      "Epoch [69/100], Loss: 1.1458, Train Accuracy: 67.20%, Test Accuracy: 64.53%\n",
      "Epoch [70/100], Loss: 1.1408, Train Accuracy: 67.41%, Test Accuracy: 64.53%\n",
      "Epoch [71/100], Loss: 1.1422, Train Accuracy: 67.09%, Test Accuracy: 64.53%\n",
      "Epoch [72/100], Loss: 1.1422, Train Accuracy: 67.10%, Test Accuracy: 64.54%\n",
      "Epoch [73/100], Loss: 1.1434, Train Accuracy: 66.95%, Test Accuracy: 64.56%\n",
      "Epoch [74/100], Loss: 1.1446, Train Accuracy: 67.06%, Test Accuracy: 64.53%\n",
      "Epoch [75/100], Loss: 1.1402, Train Accuracy: 66.94%, Test Accuracy: 64.56%\n",
      "Epoch [76/100], Loss: 1.1420, Train Accuracy: 67.19%, Test Accuracy: 64.56%\n",
      "Epoch [77/100], Loss: 1.1389, Train Accuracy: 67.64%, Test Accuracy: 64.56%\n",
      "Epoch [78/100], Loss: 1.1430, Train Accuracy: 67.03%, Test Accuracy: 64.56%\n",
      "Epoch [79/100], Loss: 1.1425, Train Accuracy: 67.56%, Test Accuracy: 64.54%\n",
      "Epoch [80/100], Loss: 1.1390, Train Accuracy: 67.44%, Test Accuracy: 64.54%\n",
      "Early stopping triggered at epoch 80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.0005  # Keep the same learning rate\n",
    "num_epochs = 100  # Set maximum epochs but add early stopping\n",
    "\n",
    "# Data Augmentation and Preprocessing (more aggressive)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),  # Resize to the original 48x48 size\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomCrop(48, padding=4),  # Random cropping with padding for variation\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # No saturation or hue needed for grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalization is correct\n",
    "])\n",
    "# Load train and test datasets\n",
    "train_dataset = datasets.ImageFolder(root='train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root='test', transform=transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "]))\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the Custom CNN Model (no increase in complexity)\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()  # ReLU comes first now\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 7)\n",
    "       \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)  # Apply ReLU first\n",
    "        x = self.bn1(x)  # Apply BN after ReLU\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)  # Apply ReLU first\n",
    "        x = self.bn2(x)  # Apply BN after ReLU\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)  # Apply ReLU first\n",
    "        x = self.bn3(x)  # Apply BN after ReLU\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "       \n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "       \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize Model, Loss Function, and Optimizer\n",
    "model = CustomCNN()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Keep label smoothing\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "# Scheduler with more aggressive learning rate decay\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # Adjusted step size\n",
    "\n",
    "# Device Configuration (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Function to Calculate Accuracy\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Early Stopping Logic\n",
    "def early_stopping(val_acc_list, patience=3):\n",
    "    if len(val_acc_list) > patience:\n",
    "        if all(val_acc_list[-i] <= val_acc_list[-i - 1] for i in range(1, patience + 1)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Evaluate the Model\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "           \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "           \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "   \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy\n",
    "\n",
    "# Training the Model with Early Stopping and LR Scheduling\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs, patience=5):\n",
    "    model.train()\n",
    "    val_acc_list = []\n",
    "   \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "       \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "       \n",
    "        # Evaluate test accuracy at the end of each epoch\n",
    "        test_accuracy = evaluate_model(model, test_loader)\n",
    "        val_acc_list.append(test_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if early_stopping(val_acc_list, patience=patience):\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f419f67-3618-42d0-91bd-e16b23212069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Model\n",
    "torch.save(model.state_dict(), 'cnn_fer2013_64percent.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
